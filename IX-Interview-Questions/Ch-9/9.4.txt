
Assume a URL is 100 characters on average.
Assume a character is 1 byte.
Thus, a URL is 100 bytes or 10^2 bytes

10,000,000,000 URLs is 10^10 URLs

Thus, we can assume we need 10^12 bytes worth of storage (1 TB)

We probably won't be able to do this all in memory. Thus, we'll use some kind
of data store (i.e. a database)

Create two tables. One table has a list of only unique URLs. Before adding
a URL to this table, make sure it doesn't already exist. A hash may make
this lookup faster. Also, the database may be able to cache frequently
accessed values. The second table can store duplicate URLs.

If duplicates are frequent and first table is long, the second table
should be searched first.

